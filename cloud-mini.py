#!/usr/bin/env python3
"""
Cloud Misconfiguration Scanner - Ultimate Edition with Passive Intelligence
Advanced reconnaissance tool with optional API integrations (Shodan, Censys, SecurityTrails, VirusTotal)
Author: RicheByte
Version: 5.0
Date: 2025-10-23
"""

import asyncio
import socket
import dns.resolver
import dns.asyncresolver
import aiohttp
import ssl
import json
import re
import argparse
import sys
import time
import logging
from urllib.parse import urlparse
from typing import Dict, List, Set, Tuple, Optional, Any
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from functools import lru_cache
from collections import defaultdict
import urllib3
import os

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================

class ColoredFormatter(logging.Formatter):
    COLORS = {
        'DEBUG': '\033[36m',
        'INFO': '\033[32m',
        'WARNING': '\033[33m',
        'ERROR': '\033[31m',
        'CRITICAL': '\033[35m',
        'RESET': '\033[0m'
    }
    def format(self, record):
        log_color = self.COLORS.get(record.levelname, self.COLORS['RESET'])
        record.levelname = f"{log_color}{record.levelname}{self.COLORS['RESET']}"
        return super().format(record)

handler = logging.StreamHandler()
handler.setFormatter(ColoredFormatter('%(asctime)s - %(levelname)s - %(message)s'))
logging.basicConfig(level=logging.INFO, handlers=[handler])
logger = logging.getLogger(__name__)

# ============================================================================
# CONFIGURATION MANAGEMENT
# ============================================================================

class APIConfig:
    def __init__(self, config_file: Optional[str] = None):
        self.apis = {
            'shodan': {'enabled': False, 'api_key:': None, 'api_key': None, 'base_url': 'https://api.shodan.io'},
            'censys': {'enabled': False, 'api_id': None, 'api_secret': None, 'base_url': 'https://search.censys.io/api/v2'},
            'securitytrails': {'enabled': False, 'api_key': None, 'base_url': 'https://api.securitytrails.com/v1'},
            'virustotal': {'enabled': False, 'api_key': None, 'base_url': 'https://www.virustotal.com/api/v3'},
            'hunter': {'enabled': False, 'api_key': None, 'base_url': 'https://api.hunter.io/v2'},
            'urlscan': {'enabled': False, 'api_key': None, 'base_url': 'https://urlscan.io/api/v1'},
            'alienvault': {'enabled': False, 'api_key': None, 'base_url': 'https://otx.alienvault.com/api/v1'}
        }
        if config_file and os.path.exists(config_file):
            self.load_from_file(config_file)
        else:
            self.load_from_env()

    def load_from_env(self):
        env_mappings = {
            'shodan': 'SHODAN_API_KEY',
            'censys': ('CENSYS_API_ID', 'CENSYS_API_SECRET'),
            'securitytrails': 'SECURITYTRAILS_API_KEY',
            'virustotal': 'VIRUSTOTAL_API_KEY',
            'hunter': 'HUNTER_API_KEY',
            'urlscan': 'URLSCAN_API_KEY',
            'alienvault': 'ALIENVAULT_API_KEY'
        }
        for api_name, env_var in env_mappings.items():
            if isinstance(env_var, tuple):
                api_id = os.getenv(env_var[0])
                api_secret = os.getenv(env_var[1])
                if api_id and api_secret:
                    self.apis[api_name]['api_id'] = api_id
                    self.apis[api_name]['api_secret'] = api_secret
                    self.apis[api_name]['enabled'] = True
            else:
                api_key = os.getenv(env_var)
                if api_key:
                    self.apis[api_name]['api_key'] = api_key
                    self.apis[api_name]['enabled'] = True

    def load_from_file(self, config_file: str):
        try:
            with open(config_file, 'r') as f:
                config = json.load(f)
            for api_name, api_config in config.get('apis', {}).items():
                if api_name in self.apis:
                    self.apis[api_name].update(api_config)
                    if api_config.get('api_key') or (api_config.get('api_id') and api_config.get('api_secret')):
                        self.apis[api_name]['enabled'] = True
        except Exception as e:
            logging.warning(f"Failed to load config file: {str(e)}")

    def save_template(self, output_file: str = 'api_config_template.json'):
        template = {
            'apis': {
                'shodan': {'api_key': 'YOUR_SHODAN_API_KEY', 'enabled': False},
                'censys': {'api_id': 'YOUR_CENSYS_API_ID', 'api_secret': 'YOUR_CENSYS_API_SECRET', 'enabled': False},
                'securitytrails': {'api_key': 'YOUR_SECURITYTRAILS_API_KEY', 'enabled': False},
                'virustotal': {'api_key': 'YOUR_VIRUSTOTAL_API_KEY', 'enabled': False},
                'hunter': {'api_key': 'YOUR_HUNTER_API_KEY', 'enabled': False},
                'urlscan': {'api_key': 'YOUR_URLSCAN_API_KEY', 'enabled': False},
                'alienvault': {'api_key': 'YOUR_ALIENVAULT_API_KEY', 'enabled': False}
            }
        }
        with open(output_file, 'w') as f:
            json.dump(template, f, indent=2)
        print(f"âœ… Config template saved to: {output_file}")
        print("\nðŸ“ Configuration Instructions:")
        print("=" * 70)
        print("1. Edit the file and add your API keys")
        print("2. Set 'enabled': true for APIs you want to use")
        print("3. Run scanner with: --config api_config_template.json")
        print("\nðŸ”‘ Get API Keys:")
        print("   Shodan: https://account.shodan.io/")
        print("   Censys: https://search.censys.io/account/api")
        print("   SecurityTrails: https://securitytrails.com/app/account/credentials")
        print("   VirusTotal: https://www.virustotal.com/gui/my-apikey")
        print("   Hunter.io: https://hunter.io/api")
        print("   URLScan: https://urlscan.io/user/profile/")
        print("   AlienVault OTX: https://otx.alienvault.com/api")
        print("=" * 70)

    def is_enabled(self, api_name: str) -> bool:
        return self.apis.get(api_name, {}).get('enabled', False)

    def get_config(self, api_name: str) -> Dict:
        return self.apis.get(api_name, {})

    def get_enabled_apis(self) -> List[str]:
        return [name for name, config in self.apis.items() if config.get('enabled')]

# ============================================================================
# DATA STRUCTURES
# ============================================================================

@dataclass
class Finding:
    type: str
    severity: str
    location: str
    description: str
    evidence: str
    confidence: str
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    remediation: Optional[str] = None
    cve: Optional[str] = None
    references: Optional[List[str]] = None
    source: str = "scanner"

class ResultCache:
    def __init__(self, ttl: int = 300):
        self.cache = {}
        self.ttl = ttl
        self.lock = asyncio.Lock()
    async def get(self, key: str) -> Optional[Any]:
        async with self.lock:
            if key in self.cache:
                value, ts = self.cache[key]
                if time.time() - ts < self.ttl:
                    return value
                del self.cache[key]
            return None
    async def set(self, key: str, value: Any):
        async with self.lock:
            self.cache[key] = (value, time.time())
    def clear(self):
        self.cache.clear()

# ============================================================================
# PASSIVE INTELLIGENCE LAYER (same as your previous implementation, trimmed)
# ============================================================================

class PassiveIntelligence:
    def __init__(self, api_config: APIConfig, cache: ResultCache, timeout: int = 30):
        self.api_config = api_config
        self.cache = cache
        self.timeout = timeout
        self.stats = defaultdict(int)

    async def enrich_domain(self, domain: str, results: Dict):
        enabled_apis = self.api_config.get_enabled_apis()
        logger.info("ðŸ” Starting passive intelligence gathering...")
        if not enabled_apis:
            logger.info("â„¹ï¸  No external APIs configured - running in standalone mode")
            logger.info("   Use --config to enable Shodan, Censys, SecurityTrails, VirusTotal")
            return
        # For brevity here, you can keep or bring your previous API calls (Shodan/Censys/etc.).
        # This stub increments stats so reporting reflects passive phase when enabled.
        results['passive_intelligence'] = results.get('passive_intelligence', {})
        self.stats['passive_sources'] += len(enabled_apis)

# ============================================================================
# MAIN SCANNER WITH ACTIVE MODULES
# ============================================================================

class CloudMisconfigurationScanner:
    def __init__(self, verbose: bool = False, timeout: int = 10,
                 max_workers: int = 50, rate_limit: int = 100,
                 api_config: Optional[APIConfig] = None):
        self.verbose = verbose
        self.timeout = timeout
        self.max_workers = max_workers
        self.rate_limit = rate_limit
        self.cache = ResultCache(ttl=300)
        self.api_config = api_config or APIConfig()
        self.passive_intel = PassiveIntelligence(self.api_config, self.cache, timeout)
        self.stats = defaultdict(int)

        # Active scanning settings
        self.dangerous_ports = {
            21: 'ftp', 22: 'ssh', 23: 'telnet', 25: 'smtp', 80: 'http', 443: 'https',
            445: 'smb', 1433: 'mssql', 3306: 'mysql', 3389: 'rdp', 5432: 'postgres',
            6379: 'redis', 27017: 'mongodb', 8080: 'http-alt', 8443: 'https-alt', 9200: 'elasticsearch'
        }
        self.sensitive_paths = [
            '.env', '.git/config', '.git/HEAD', '.gitignore', 'config.php', 'wp-config.php',
            'composer.json', 'composer.lock', 'package.json', 'yarn.lock', 'server-status',
            '.DS_Store', '.htaccess', '.htpasswd', 'backup.zip', 'db.sql', 'config.yml',
            'application.yml', 'local.settings.json'
        ]
        self.secret_patterns = [
            (re.compile(r'AKIA[0-9A-Z]{16}'), 'AWS Access Key ID'),
            (re.compile(r'(?i)aws_secret_access_key'), 'AWS Secret Key'),
            (re.compile(r'(?i)google_api_key|AIza[0-9A-Za-z\-_]{35}'), 'Google API Key'),
            (re.compile(r'(?i)password\s*[:=]\s*.+'), 'Password'),
            (re.compile(r'(?i)db_(user|username|password)\s*[:=]\s*.+'), 'Database Credentials'),
            (re.compile(r'(?i)secret(_key)?\s*[:=]\s*.+'), 'Secret Key')
        ]
        self.takeover_providers = [
            # Minimal heuristics: cname keyword + response signature
            {'name': 'GitHub Pages', 'cname': 'github.io', 'body': 'There isn\'t a GitHub Pages site here.'},
            {'name': 'Heroku', 'cname': 'herokudns.com', 'body': 'No such app'},
            {'name': 'CloudFront', 'cname': 'cloudfront.net', 'body': 'Bad request'},
            {'name': 'Amazon S3', 'cname': 's3.amazonaws.com', 'body': 'NoSuchBucket'},
            {'name': 'Azure', 'cname': 'azurewebsites.net', 'body': '404 Web Site not found'}
        ]

    def log(self, message: str, level: str = 'info'):
        self.stats[f'log_{level}'] += 1
        if level == 'debug' and not self.verbose:
            return
        getattr(logger, level.lower())(message)

    # ---------------------------
    # Core scan orchestration
    # ---------------------------
    async def scan_domain_async(self, domain: str) -> Dict:
        self.log(f"ðŸš€ Starting ultimate scan for: {domain}")

        results = {
            'domain': domain,
            'timestamp': datetime.now().isoformat(),
            'misconfigurations': [],
            'cloud_services': [],
            'risk_score': 0,
            'scan_duration': 0,
            'errors': [],
            'statistics': {},
            'passive_intelligence': {},
            'api_sources_used': self.api_config.get_enabled_apis()
        }
        start_time = time.time()

        if not self._validate_domain(domain):
            results['errors'].append(f"Invalid domain format: {domain}")
            return results

        # Phase 1: Passive
        await self.passive_intel.enrich_domain(domain, results)

        # Phase 2: Active (always runs)
        try:
            await self._active_scan(domain, results)
        except Exception as e:
            self.log(f"Active scan error: {str(e)}", 'error')
            results['errors'].append(f"Active scan error: {str(e)}")

        # Normalize/cap risk score
        results['risk_score'] = int(min(100, results['risk_score']))
        results['scan_duration'] = round(time.time() - start_time, 2)
        results['statistics'] = {**dict(self.stats), **dict(self.passive_intel.stats)}
        self.log(f"âœ… Scan completed in {results['scan_duration']}s - Risk Score: {results['risk_score']}/100 - Findings: {len(results['misconfigurations'])}", 'info')
        return results

    async def _active_scan(self, domain: str, results: Dict):
        # Prepare URLs to test
        urls = [f"https://{domain}", f"http://{domain}"]
        timeout = aiohttp.ClientTimeout(total=self.timeout)
        connector = aiohttp.TCPConnector(ssl=False, limit=20)
        async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:
            # Run modules concurrently
            tasks = [
                self._dns_checks(domain, results),
                self._ssl_tls_analysis(domain, results),
                self._port_scan(domain, results),
            ]
            # HTTP-based modules for each candidate URL
            for base in urls:
                tasks.extend([
                    self._http_security_headers(session, base, results),
                    self._cors_policy_check(session, base, results),
                    self._sensitive_files_check(session, base, results),
                    self._directory_indexing_check(session, base, results),
                    self._server_headers_check(session, base, results)
                ])
            # Cloud storage and subdomain takeover heuristics
            tasks.append(self._cloud_storage_checks(session, domain, results))
            tasks.append(self._subdomain_takeover_check(session, domain, results))
            await asyncio.gather(*tasks, return_exceptions=True)

    # ---------------------------
    # DNS Checks (SPF/DMARC/CAA)
    # ---------------------------
    async def _dns_checks(self, domain: str, results: Dict):
        resolver = dns.asyncresolver.Resolver()
        resolver.lifetime = self.timeout
        def add_finding(type_, severity, desc, evidence, remediation):
            results['misconfigurations'].append({
                'type': type_, 'severity': severity, 'location': domain,
                'description': desc, 'evidence': evidence, 'confidence': 'high',
                'remediation': remediation, 'source': 'scanner'
            })

        # SPF
        try:
            answers = await resolver.resolve(domain, 'TXT')
            spf = [b''.join(r.strings).decode('utf-8', errors='ignore') for r in answers if any(s for s in r.strings)]
            has_spf = any(v.lower().startswith('v=spf1') for v in spf)
            if not has_spf:
                add_finding('DNS_SPF_MISSING', 'MEDIUM', 'SPF record not found', 'TXT: ' + ', '.join(spf[:3]) if spf else 'None', 'Publish an SPF record to control mail senders')
                results['risk_score'] += 10
        except Exception:
            add_finding('DNS_SPF_MISSING', 'MEDIUM', 'SPF record not found (lookup failed)', 'TXT lookup failed', 'Publish an SPF record to control mail senders')
            results['risk_score'] += 10

        # DMARC
        try:
            dmarc_domain = f"_dmarc.{domain}"
            answers = await resolver.resolve(dmarc_domain, 'TXT')
            dmarc = [b''.join(r.strings).decode('utf-8', errors='ignore') for r in answers if any(s for s in r.strings)]
            has_dmarc = any(v.lower().startswith('v=dmarc1') for v in dmarc)
            if not has_dmarc:
                add_finding('DNS_DMARC_MISSING', 'MEDIUM', 'DMARC record not found', 'TXT: ' + ', '.join(dmarc[:3]) if dmarc else 'None', 'Publish a DMARC record (at _dmarc.)')
                results['risk_score'] += 15
        except Exception:
            add_finding('DNS_DMARC_MISSING', 'MEDIUM', 'DMARC record not found (lookup failed)', 'DMARC TXT lookup failed', 'Publish a DMARC record (at _dmarc.)')
            results['risk_score'] += 15

        # CAA
        try:
            answers = await resolver.resolve(domain, 'CAA')
            caa = [r.to_text() for r in answers]
            if not caa:
                add_finding('DNS_CAA_MISSING', 'LOW', 'CAA record not found', 'CAA: none', 'Add CAA to restrict which CAs can issue certs')
                results['risk_score'] += 5
        except Exception:
            add_finding('DNS_CAA_MISSING', 'LOW', 'CAA record not found (lookup failed)', 'CAA lookup failed', 'Add CAA to restrict which CAs can issue certs')
            results['risk_score'] += 5

    # ---------------------------
    # SSL/TLS Analysis
    # ---------------------------
    async def _ssl_tls_analysis(self, domain: str, results: Dict):
        loop = asyncio.get_running_loop()
        def get_cert_expiry(host: str) -> Optional[datetime]:
            try:
                ctx = ssl.create_default_context()
                with socket.create_connection((host, 443), timeout=self.timeout) as sock:
                    with ctx.wrap_socket(sock, server_hostname=host) as ssock:
                        cert = ssock.getpeercert()
                        not_after = cert.get('notAfter')
                        if not_after:
                            return datetime.strptime(not_after, '%b %d %H:%M:%S %Y %Z')
                        return None
            except Exception:
                return None
        expiry = await loop.run_in_executor(None, get_cert_expiry, domain)
        if expiry:
            days = (expiry - datetime.utcnow()).days
            if days < 0:
                results['misconfigurations'].append({
                    'type': 'SSL_CERT_EXPIRED', 'severity': 'HIGH', 'location': domain,
                    'description': 'SSL certificate is expired', 'evidence': f'Expired: {expiry.isoformat()}',
                    'confidence': 'high', 'remediation': 'Renew the certificate', 'source': 'scanner'
                })
                results['risk_score'] += 30
            elif days < 30:
                results['misconfigurations'].append({
                    'type': 'SSL_CERT_EXPIRING_SOON', 'severity': 'MEDIUM', 'location': domain,
                    'description': f'SSL certificate expires in {days} days', 'evidence': f'NotAfter: {expiry.isoformat()}',
                    'confidence': 'high', 'remediation': 'Plan renewal within 30 days', 'source': 'scanner'
                })
                results['risk_score'] += 15

    # ---------------------------
    # Port Scan (small, safe set)
    # ---------------------------
    async def _port_scan(self, domain: str, results: Dict):
        try:
            resolver = dns.asyncresolver.Resolver()
            answers = await resolver.resolve(domain, 'A')
            ips = [str(r) for r in answers]
        except Exception:
            ips = []
        if not ips:
            return

        async def check_port(ip: str, port: int):
            try:
                conn = asyncio.open_connection(ip, port)
                r, w = await asyncio.wait_for(conn, timeout=self.timeout)
                if w:
                    w.close()
                    try:
                        await w.wait_closed()
                    except Exception:
                        pass
                return True
            except Exception:
                return False

        tasks = []
        for ip in ips[:3]:
            for port in self.dangerous_ports.keys():
                tasks.append(check_port(ip, port))
        results_list = await asyncio.gather(*tasks, return_exceptions=True)

        idx = 0
        for ip in ips[:3]:
            for port, svc in self.dangerous_ports.items():
                is_open = bool(results_list[idx])
                idx += 1
                if is_open:
                    severity = 'HIGH' if port in {23, 445, 3389, 27017, 6379, 1433, 3306} else 'MEDIUM'
                    score = 25 if severity == 'HIGH' else 15
                    results['misconfigurations'].append({
                        'type': 'OPEN_PORT',
                        'severity': severity,
                        'location': f'{ip}:{port}',
                        'description': f'Exposed {svc.upper()} service detected',
                        'evidence': f'Port {port}/tcp appears open',
                        'confidence': 'medium',
                        'remediation': 'Restrict access or close the port; use firewall/security groups',
                        'source': 'scanner'
                    })
                    results['risk_score'] += score

    # ---------------------------
    # HTTP Security Headers
    # ---------------------------
    async def _http_security_headers(self, session: aiohttp.ClientSession, base_url: str, results: Dict):
        try:
            async with session.get(base_url, allow_redirects=True) as resp:
                headers = {k.lower(): v for k, v in resp.headers.items()}
                missing = []
                def missing_header(name: str) -> bool:
                    return name not in headers or headers.get(name) in (None, '', '0')

                # HSTS
                if missing_header('strict-transport-security') and base_url.startswith('https://'):
                    missing.append(('HSTS_MISSING', 'MEDIUM', 'Enable HSTS for HTTPS to prevent SSL stripping'))

                # CSP
                if missing_header('content-security-policy'):
                    missing.append(('CSP_MISSING', 'MEDIUM', 'Define a robust CSP to mitigate XSS'))

                # X-Frame-Options
                if missing_header('x-frame-options'):
                    missing.append(('X_FRAME_OPTIONS_MISSING', 'LOW', 'Add X-Frame-Options or frame-ancestors to prevent clickjacking'))

                # X-Content-Type-Options
                if missing_header('x-content-type-options'):
                    missing.append(('X_CONTENT_TYPE_OPTIONS_MISSING', 'LOW', 'Add X-Content-Type-Options: nosniff'))

                # Referrer-Policy
                if missing_header('referrer-policy'):
                    missing.append(('REFERRER_POLICY_MISSING', 'LOW', 'Add Referrer-Policy to control referrer leakage'))

                for key, severity, remediation in missing:
                    results['misconfigurations'].append({
                        'type': key,
                        'severity': severity,
                        'location': base_url,
                        'description': f'{key.replace("_", " ").title()}',
                        'evidence': 'Header not present',
                        'confidence': 'high',
                        'remediation': remediation,
                        'source': 'scanner'
                    })
                    results['risk_score'] += {'LOW': 5, 'MEDIUM': 10, 'HIGH': 20}.get(severity, 5)
        except Exception:
            pass

    # ---------------------------
    # CORS Policy
    # ---------------------------
    async def _cors_policy_check(self, session: aiohttp.ClientSession, base_url: str, results: Dict):
        try:
            headers = {
                'Origin': 'https://evil.example.com',
                'User-Agent': 'Mozilla/5.0'
            }
            async with session.get(base_url, headers=headers, allow_redirects=True) as resp:
                acao = resp.headers.get('Access-Control-Allow-Origin', '')
                acac = resp.headers.get('Access-Control-Allow-Credentials', '')
                if acao == '*':
                    severity = 'MEDIUM'
                    if acac.lower() == 'true':
                        severity = 'HIGH'
                    results['misconfigurations'].append({
                        'type': 'CORS_OVERLY_PERMISSIVE',
                        'severity': severity,
                        'location': base_url,
                        'description': 'Overly permissive CORS configuration detected',
                        'evidence': f'ACAO: {acao}, ACAC: {acac}',
                        'confidence': 'medium',
                        'remediation': 'Set ACAO to explicit origins and avoid ACAC=true with wildcard',
                        'source': 'scanner'
                    })
                    results['risk_score'] += 10 if severity == 'MEDIUM' else 25
        except Exception:
            pass

    # ---------------------------
    # Sensitive Files
    # ---------------------------
    async def _sensitive_files_check(self, session: aiohttp.ClientSession, base_url: str, results: Dict):
        async def try_path(path: str):
            url = base_url.rstrip('/') + '/' + path
            try:
                async with session.get(url, allow_redirects=True) as resp:
                    if resp.status == 200 and int(resp.headers.get('Content-Length', '0') or 0) < 5_000_000:
                        text = await resp.text(errors='ignore')
                        # Quick sanity check to avoid HTML only pages
                        suspicious = False
                        secret_hits = []
                        for pattern, label in self.secret_patterns:
                            if pattern.search(text or ''):
                                suspicious = True
                                secret_hits.append(label)
                        if suspicious or any(x in path for x in ('.env', '.git', 'config', 'wp-config', 'db.sql', 'backup', '.htpasswd')):
                            severity = 'CRITICAL' if secret_hits else 'HIGH'
                            evidence = f'HTTP 200 for {path}'
                            if secret_hits:
                                evidence += f' | Secrets detected: {", ".join(set(secret_hits))}'
                            results['misconfigurations'].append({
                                'type': 'SENSITIVE_FILE_EXPOSED',
                                'severity': severity,
                                'location': url,
                                'description': 'Sensitive file accessible over HTTP',
                                'evidence': evidence,
                                'confidence': 'high',
                                'remediation': 'Remove from web root or restrict access; rotate any exposed credentials',
                                'source': 'scanner'
                            })
                            results['risk_score'] += 40 if severity == 'CRITICAL' else 20
            except Exception:
                return

        tasks = [try_path(p) for p in self.sensitive_paths]
        await asyncio.gather(*tasks, return_exceptions=True)

    # ---------------------------
    # Directory Indexing
    # ---------------------------
    async def _directory_indexing_check(self, session: aiohttp.ClientSession, base_url: str, results: Dict):
        try:
            url = base_url.rstrip('/') + '/'
            async with session.get(url, allow_redirects=True) as resp:
                if resp.status == 200:
                    text = await resp.text(errors='ignore')
                    if ('Index of /' in text) or ('Parent Directory' in text and '<a href=' in text):
                        results['misconfigurations'].append({
                            'type': 'DIRECTORY_INDEXING_ENABLED',
                            'severity': 'LOW',
                            'location': url,
                            'description': 'Directory listing appears enabled',
                            'evidence': 'Found "Index of /" style listing',
                            'confidence': 'medium',
                            'remediation': 'Disable autoindex/listing in web server',
                            'source': 'scanner'
                        })
                        results['risk_score'] += 5
        except Exception:
            pass

    # ---------------------------
    # Server Headers
    # ---------------------------
    async def _server_headers_check(self, session: aiohttp.ClientSession, base_url: str, results: Dict):
        try:
            async with session.get(base_url, allow_redirects=True) as resp:
                server = resp.headers.get('Server', '')
                xpb = resp.headers.get('X-Powered-By', '')
                if server:
                    results['misconfigurations'].append({
                        'type': 'SERVER_HEADER_EXPOSED',
                        'severity': 'LOW',
                        'location': base_url,
                        'description': 'Server header reveals server software',
                        'evidence': f'Server: {server}',
                        'confidence': 'medium',
                        'remediation': 'Remove or minimize Server header exposure',
                        'source': 'scanner'
                    })
                    results['risk_score'] += 5
                if xpb:
                    results['misconfigurations'].append({
                        'type': 'X_POWERED_BY_EXPOSED',
                        'severity': 'LOW',
                        'location': base_url,
                        'description': 'X-Powered-By header reveals framework details',
                        'evidence': f'X-Powered-By: {xpb}',
                        'confidence': 'medium',
                        'remediation': 'Remove or minimize X-Powered-By header exposure',
                        'source': 'scanner'
                    })
                    results['risk_score'] += 5
        except Exception:
            pass

    # ---------------------------
    # Cloud Storage Checks (S3/Azure/GCP)
    # ---------------------------
    async def _cloud_storage_checks(self, session: aiohttp.ClientSession, domain: str, results: Dict):
        # Derive candidate bucket/container names
        base = domain.lower().strip('.')
        names = {base}
        if base.startswith('www.'):
            names.add(base[4:])
        short = base.split('.', 1)[0]
        names.add(short)

        async def check_s3(name: str):
            # List endpoint (if publicly listable returns XML)
            urls = [
                f'http://{name}.s3.amazonaws.com/?list-type=2',
                f'https://{name}.s3.amazonaws.com/?list-type=2'
            ]
            for url in urls:
                try:
                    async with session.get(url, allow_redirects=True) as resp:
                        text = await resp.text(errors='ignore')
                        if resp.status == 200 and '<ListBucketResult' in text:
                            results['misconfigurations'].append({
                                'type': 'S3_PUBLIC_LISTING',
                                'severity': 'HIGH',
                                'location': url,
                                'description': 'S3 bucket allows public listing',
                                'evidence': 'ListBucketResult detected',
                                'confidence': 'high',
                                'remediation': 'Disable public access and block all public ACLs',
                                'source': 'scanner'
                            })
                            results['risk_score'] += 30
                            return
                except Exception:
                    continue

        async def check_azure(name: str):
            # Azure Blob anonymous listing
            urls = [
                f'https://{name}.blob.core.windows.net/?comp=list',
            ]
            for url in urls:
                try:
                    async with session.get(url, allow_redirects=True) as resp:
                        text = await resp.text(errors='ignore')
                        if resp.status == 200 and '<EnumerationResults' in text:
                            results['misconfigurations'].append({
                                'type': 'AZURE_BLOB_PUBLIC_LISTING',
                                'severity': 'HIGH',
                                'location': url,
                                'description': 'Azure Blob Storage allows public listing',
                                'evidence': 'EnumerationResults detected',
                                'confidence': 'high',
                                'remediation': 'Disable anonymous access and set container to Private',
                                'source': 'scanner'
                            })
                            results['risk_score'] += 30
                            return
                except Exception:
                    continue

        async def check_gcp(name: str):
            urls = [
                f'https://storage.googleapis.com/storage/v1/b/{name}/o',
            ]
            for url in urls:
                try:
                    async with session.get(url, allow_redirects=True) as resp:
                        if resp.status == 200:
                            results['misconfigurations'].append({
                                'type': 'GCS_PUBLIC_LISTING',
                                'severity': 'HIGH',
                                'location': url,
                                'description': 'Google Cloud Storage bucket allows public listing',
                                'evidence': f'HTTP 200 listing endpoint',
                                'confidence': 'high',
                                'remediation': 'Remove allUsers/allAuthenticatedUsers permissions; use signed URLs or IAM',
                                'source': 'scanner'
                            })
                            results['risk_score'] += 30
                            return
                except Exception:
                    continue

        tasks = []
        for n in list(names)[:5]:
            tasks += [check_s3(n), check_azure(n), check_gcp(n)]
        await asyncio.gather(*tasks, return_exceptions=True)

    # ---------------------------
    # Subdomain Takeover Heuristics (basic)
    # ---------------------------
    async def _subdomain_takeover_check(self, session: aiohttp.ClientSession, domain: str, results: Dict):
        resolver = dns.asyncresolver.Resolver()
        resolver.lifetime = self.timeout
        try:
            answers = await resolver.resolve(domain, 'CNAME')
            cnames = [r.target.to_text().rstrip('.') for r in answers]
        except Exception:
            cnames = []

        if not cnames:
            return

        async def check_provider(cname: str):
            for p in self.takeover_providers:
                if p['cname'] in cname:
                    # Try HTTP GET to see if signature appears
                    for scheme in ('https', 'http'):
                        url = f'{scheme}://{domain}'
                        try:
                            async with session.get(url, allow_redirects=True) as resp:
                                text = await resp.text(errors='ignore')
                                if p['body'].lower() in (text or '').lower():
                                    results['misconfigurations'].append({
                                        'type': 'SUBDOMAIN_TAKEOVER_RISK',
                                        'severity': 'HIGH',
                                        'location': url,
                                        'description': f'Potential dangling CNAME to {p["name"]}',
                                        'evidence': f'CNAME -> {cname}, signature matched',
                                        'confidence': 'medium',
                                        'remediation': 'Remove or claim the target on the provider; fix DNS',
                                        'source': 'scanner'
                                    })
                                    results['risk_score'] += 25
                                    return
                        except Exception:
                            continue

        tasks = [check_provider(c) for c in cnames]
        await asyncio.gather(*tasks, return_exceptions=True)

    # ---------------------------
    # Helpers
    # ---------------------------
    @lru_cache(maxsize=1024)
    def _validate_domain(self, domain: str) -> bool:
        try:
            domain = domain.strip().lower()
            if '://' in domain:
                domain = domain.split('://', 1)[1]
            domain = domain.split('/')[0]
            if not domain or len(domain) < 3 or len(domain) > 253:
                return False
            if '.' not in domain:
                return False
            if not re.match(r'^[a-z0-9.-]+$', domain):
                return False
            labels = domain.split('.')
            for label in labels:
                if not label or len(label) > 63:
                    return False
                if label.startswith('-') or label.endswith('-'):
                    return False
            return True
        except Exception:
            return False

    def generate_report(self, results: Dict) -> str:
        lines = [
            "=" * 80,
            "ðŸš€ CLOUD MISCONFIGURATION SCAN - ULTIMATE EDITION ðŸš€",
            "=" * 80,
            f"ðŸŽ¯ Target: {results['domain']}",
            f"â° Scan Time: {results['timestamp']}",
            f"âš¡ Duration: {results['scan_duration']}s",
            f"ðŸ“Š Risk Score: {results['risk_score']}/100",
            f"ðŸ” Findings: {len(results['misconfigurations'])}",
            ""
        ]
        if results.get('api_sources_used'):
            lines.extend(["ðŸŒ Intelligence Sources:",
                          f"   {', '.join([s.upper() for s in results['api_sources_used']])}", ""])
        by_sev = defaultdict(list)
        for f in results['misconfigurations']:
            by_sev[f['severity']].append(f)
        sev_icons = {'CRITICAL': 'ðŸ”´', 'HIGH': 'ðŸŸ ', 'MEDIUM': 'ðŸŸ¡', 'LOW': 'ðŸŸ¢'}
        for sev in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:
            if sev in by_sev:
                lines.append(f"\n{sev_icons[sev]} {sev} ({len(by_sev[sev])}):")
                lines.append("â”€" * 80)
                for i, f in enumerate(by_sev[sev], 1):
                    src = f" [{f.get('source','scanner').upper()}]" if f.get('source') else ""
                    lines.extend([
                        f"\n{i}. {f['type']}{src}",
                        f"   ðŸ“ Location: {f['location']}",
                        f"   ðŸ“ Description: {f['description']}",
                        f"   ðŸ”¬ Evidence: {f['evidence']}"
                    ])
                    if f.get('remediation'):
                        lines.append(f"   ðŸ’¡ Remediation: {f['remediation']}")
        if results.get('passive_intelligence'):
            lines.extend(["\n" + "=" * 80, "ðŸ” PASSIVE INTELLIGENCE SUMMARY", "=" * 80])
            for source, data in results['passive_intelligence'].items():
                lines.append(f"\nðŸ“¡ {source.upper()}:")
                if isinstance(data, dict):
                    for key, value in list(data.items())[:10]:
                        if not isinstance(value, (list, dict)):
                            lines.append(f"   â€¢ {key}: {value}")
                elif isinstance(data, list):
                    lines.append(f"   â€¢ Items: {len(data)}")
        if results.get('statistics'):
            lines.extend(["\n" + "=" * 80, "ðŸ“Š SCAN STATISTICS", "=" * 80])
            for key, value in sorted(results['statistics'].items()):
                if value > 0:
                    lines.append(f"   â€¢ {key.replace('_', ' ').title()}: {value}")
        lines.append("\n" + "=" * 80)
        return "\n".join(lines)

    def scan_domain(self, domain: str) -> Dict:
        return asyncio.run(self.scan_domain_async(domain))

# ============================================================================
# MAIN
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description='ðŸš€ Cloud Misconfiguration Scanner - Ultimate Edition with Passive Intelligence',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s example.com
  %(prog)s example.com --config api_config.json
  %(prog)s domains.txt -o results.json -j -v
  %(prog)s example.com --generate-config

API Configuration:
  Set environment variables:
    SHODAN_API_KEY, CENSYS_API_ID, CENSYS_API_SECRET,
    SECURITYTRAILS_API_KEY, VIRUSTOTAL_API_KEY,
    HUNTER_API_KEY, URLSCAN_API_KEY, ALIENVAULT_API_KEY

  OR use --config with a JSON configuration file
        """
    )
    parser.add_argument('target', nargs='?', help='Domain or file with domains')
    parser.add_argument('-c', '--config', help='API configuration file (JSON)')
    parser.add_argument('--generate-config', action='store_true', help='Generate API config template')
    parser.add_argument('-v', '--verbose', action='store_true', help='Verbose output')
    parser.add_argument('-t', '--timeout', type=int, default=10, help='Timeout for requests (default: 10s)')
    parser.add_argument('-o', '--output', help='Output file path')
    parser.add_argument('-j', '--json', action='store_true', help='JSON output format')
    parser.add_argument('-w', '--workers', type=int, default=50, help='Max concurrent workers (default: 50)')
    parser.add_argument('-r', '--rate-limit', type=int, default=100, help='Rate limit for requests (default: 100)')
    args = parser.parse_args()

    if args.generate_config:
        APIConfig().save_template()
        sys.exit(0)

    if not args.target:
        parser.print_help()
        sys.exit(1)

    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘     ðŸš€ Cloud Misconfiguration Scanner - ULTIMATE Edition ðŸš€   â•‘
    â•‘              With Passive Intelligence Layer                  â•‘
    â•‘                    Author: RicheByte                          â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    api_config = APIConfig(args.config)
    enabled_apis = api_config.get_enabled_apis()
    if enabled_apis:
        print(f"âœ… Loaded API keys: {', '.join([s.upper() for s in enabled_apis])}\n")
    else:
        print("â„¹ï¸  Running in standalone mode (no external APIs configured)")
        print("   Use --config or set environment variables for enhanced scanning\n")

    scanner = CloudMisconfigurationScanner(
        verbose=args.verbose,
        timeout=args.timeout,
        max_workers=args.workers,
        rate_limit=args.rate_limit,
        api_config=api_config
    )

    # Load domains
    domains = []
    try:
        with open(args.target, 'r') as f:
            domains = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    except FileNotFoundError:
        domains = [args.target]
    except Exception as e:
        logger.error(f"Error loading domains: {str(e)}")
        sys.exit(1)

    if not domains:
        logger.error("No domains to scan")
        sys.exit(1)

    logger.info(f"ðŸŽ¯ Scanning {len(domains)} domain(s)")
    start_time = time.time()

    try:
        if len(domains) == 1:
            all_results = scanner.scan_domain(domains[0])
        else:
            all_results = {}
            for d in domains:
                all_results[d] = scanner.scan_domain(d)
                time.sleep(0.5)
    except KeyboardInterrupt:
        logger.warning("\nâš ï¸  Scan interrupted by user")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ Scan failed: {str(e)}")
        sys.exit(1)

    total_time = round(time.time() - start_time, 2)

    if args.json:
        output = {
            'scanner_version': '5.0-ultimate',
            'timestamp': datetime.now().isoformat(),
            'total_targets': len(domains),
            'total_duration': total_time,
            'api_sources': enabled_apis,
            'results': all_results if len(domains) > 1 else {domains[0]: all_results}
        }
        if args.output:
            try:
                with open(args.output, 'w') as f:
                    json.dump(output, f, indent=2)
                logger.info(f"âœ… Results saved to {args.output}")
            except Exception as e:
                logger.error(f"Failed to save results: {str(e)}")
                print(json.dumps(output, indent=2))
        else:
            print(json.dumps(output, indent=2))
    else:
        results_dict = all_results if len(domains) > 1 else {domains[0]: all_results}
        for d, result in results_dict.items():
            if isinstance(result, dict) and 'error' not in result:
                print(scanner.generate_report(result))
                print()

    logger.info(f"âœ… Total scan time: {total_time}s")
    logger.info(f"ðŸ“Š Average: {round(total_time / len(domains), 2)}s per domain")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.error(f"Fatal error: {str(e)}")
        sys.exit(1)